{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/CorndelDataAnalyticsDiploma/workshop/blob/master/Corndel%20Digital%20Logo%20Centre.png?raw=true\" alt=\"Corndel\" width =\"301.5\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xJrtZxbh8vR"
   },
   "source": [
    "# Predictive Modelling\n",
    "\n",
    "In this notebook we will build a Linear Predictive Model.\n",
    "\n",
    "## The Statisticians' Approach vs the Machine Learning Approach\n",
    "\n",
    "### The Statisticians' Approach (Recap)\n",
    "\n",
    "In the first section we built a linear model using the traditional statisticians' approach, whose focus was on **gaining understanding about the relationships between the dependent and independent variables** e.g. how much do the independent variables impact on the dependent variable?\n",
    "\n",
    "This approach is predicated on **a number of assumptions** about the data (e.g. linearity, a normal distribution of residuals and a lack of collinearity between the independent variables)\n",
    "\n",
    "### The Machine Learning Approach\n",
    "\n",
    "The focus of the Machine Learning (ML) approach is on **making predictions** i.e. how good is the model at making predictions?\n",
    "\n",
    "It still makes assumptions, but these are **less strict**.\n",
    "\n",
    "We determine how good the model is by **evaluating it against data it has not seen before**. How well does the model generalise to new data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DrB4AD4h8vX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "We will start with Simple Linear Regression (i.e. 1 independent variable) and gradually build in more independent variables. This is called **forward selection**.\n",
    "\n",
    "This is a very simple method of working out which combination of independent variables we should use in the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOxM2a1Lh8w3"
   },
   "source": [
    "Diabetes dataset\n",
    "----------------\n",
    "\n",
    "Ten baseline variables, age, sex, body mass index, average blood\n",
    "pressure, and six blood serum measurements were obtained for each of n =\n",
    "442 diabetes patients, as well as the response of interest, a\n",
    "quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "**Data Set Characteristics:**\n",
    "\n",
    "Number of rows: 442\n",
    "\n",
    "Number of columns: First 10 columns are numeric predictive values\n",
    "\n",
    "Target: Column 11 (`Y`) is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Attribute Information:\n",
    "- Age\n",
    "- Sex\n",
    "- BMI - Body mass index\n",
    "- BP - average blood pressure\n",
    "- S1...S6 - blood serum measurements 1-6\n",
    "\n",
    "Source URL:\n",
    "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "\n",
    "For more information see:\n",
    "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
    "(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "xrQIFXYbh8wY",
    "outputId": "de5e7d4c-6f41-4b7b-e7a4-d5df2bdc62ed"
   },
   "outputs": [],
   "source": [
    "# Load the diabetes dataset and display the head\n",
    "df_dia = pd.read_csv(\"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\",sep=\"\\t\")\n",
    "df_dia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "#### Any issues with this data?\n",
    "    \n",
    "    --Encoding of Sex is an issue\n",
    "    \n",
    "    -- We will address later but discuss now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to practice encoding categorical variables, this is covered is covered in the extension `Encoding.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on encoding\n",
    "\n",
    "Categorical encoding, ordinal, one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤–`*\"can i encode male and female as 1 and 2 for linear regression model?\"*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AI Chatbot will warn about issues with this and offer solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Examine the data. Does it look like there is a linear relationship?\n",
    "\n",
    "Is a linear model suitable?\n",
    "\n",
    "Do you see any outliers?\n",
    "\n",
    "What options do you have to deal with outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a description of the data\n",
    "df_dia.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to generate histograms of all columns, bins = 50 and figsize= (20,20) \n",
    "# note: no easy way to do this in Seaborn\n",
    "\n",
    "df_dia.hist(figsize = (20,20),bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Obervations\n",
    "You will notice that BMI, S3 and the dependent variable (`Y`) are all skewed.\\\n",
    "Transformations should be applied to these columns.\\\n",
    "This is covered in the extension material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use Seaborn to generate Pair Plots\n",
    "\n",
    "sns.pairplot(df_dia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Observations\n",
    "We can see S1 and S2 are highly correlated (see centre of grid). \n",
    "\n",
    "This would be an issue for Regression Analysis, but does not concern us for predictive modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a candidate independent variable (`S5`) against the dependent variable (`Y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_dia, x=\"S5\", y=\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look hugely linear but let's calculate its correlation coefficient (r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficient and its p-value\n",
    "correlation, p_value = stats.pearsonr(df_dia['S5'], df_dia['Y'])\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {round(correlation, 2)}\")\n",
    "print(f\"P-value: {round(p_value, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must divide the data into:\n",
    " - a Training set and \n",
    "  - a Test set \n",
    "  - with a 70:30 split\n",
    "  \n",
    "We will build the model using the training data and asses how well our model performs on the test data.\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "To test assess how well our model performs we will use both:\n",
    " - Root Mean Squared Error (RMSE) and \n",
    "  - Mean Absolute Percentage Error (MAPE). \n",
    "  \n",
    " We will look at these in detail later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine columns again\n",
    "\n",
    "df_dia.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Inputs to X and output to y. I copied and pasted these from the above output.\n",
    "\n",
    "X = df_dia[['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']]\n",
    "y = df_dia['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scikit-Learn to split the data into training and test sets\n",
    "# By default, train_test_split() does random sampling with shuffling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/TrainTestDiagram.png\" alt=\"Corndel\" width =\"600\" align=\"centre\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the diagram above, the approach is to:\n",
    "\n",
    "1) build a model using the training data\n",
    "2) try to build a better model using the training data (and repeat)\n",
    "3) pick the best model and evaluate it using the test data (to see how well it performs on 'unknown' data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the test and train sets.\n",
    "\n",
    "Discussion about stratfied samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Stratified.jpg\" alt=\"Corndel\" width =\"600\" align=\"centre\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Numerically examine the X_train split\n",
    "\n",
    "X_train.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Numerically examine the X_test split\n",
    "X_test.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Discussion\n",
    "    What do you notice about the two samples?\n",
    "    In which ways are they similar?\n",
    "    In which ways are they dissimilar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Numerically examine the y_train split\n",
    "# (to_frame() just converts a pandas Series into a DataFrame).\n",
    "\n",
    "y_train.to_frame().describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerically examine the y_test split\n",
    "\n",
    "y_test.to_frame().describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will build our first model using the S5 marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Seaborn to create a scatter plot of S5 against Y\n",
    "\n",
    "sns.scatterplot(data=df_dia, x=\"S5\", y=\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model and make predictions.\n",
    "\n",
    "You will note that we do not print out a model summary anymore. In this instance we are not concered about estimating coefficients and the statistical significance of these estimates.  \n",
    "\n",
    "Our focus is **how well we can make predictions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected a single independent variable\n",
    "X = X_train['S5']\n",
    "# Add a constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = y_train\n",
    "\n",
    "# Fit model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# make predictions\n",
    "#pred = model.predict(sm.add_constant(X_test['S5']))\n",
    "pred = model.predict(sm.add_constant(X_train['S5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the output, look at the predictions and the test set\n",
    "\n",
    "Notice how the indexes line up - now we can get metrics for our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine predictions\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine true values\n",
    "#y_test\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Discussion\n",
    "    What do you notice about the two samples?\n",
    "    In which ways are they similar?\n",
    "    In which ways are they dissimilar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "\n",
    "An *error* is the difference between an *actual value* and a *predicted value*. It doesn't mean \"mistake\". ðŸ˜‰\n",
    "\n",
    "RMSE measures how many \"units\" of the dependent variable we are off, on average.\n",
    "The \"Root Mean Squared\" ensures it is always positive.\n",
    "\n",
    "A **lower** RMSE value is better.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Root_mean_square_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikit-Learn Package to calculate RMSE\n",
    "# rmse = root_mean_squared_error(y_test, pred).round(2)\n",
    "rmse = root_mean_squared_error(y_train, pred).round(2)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Percentage Error (MAPE)\n",
    "This measures what *percentage* we are off on average.\\\n",
    "The \"Absolute\" ensures it is always positive.\n",
    "\n",
    "A **lower** MAPE value is better.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikit-Learn Package to calculate RMSE\n",
    "#mape = mean_absolute_percentage_error(y_test, pred).round(2)*100\n",
    "mape = mean_absolute_percentage_error(y_train, pred).round(2)*100\n",
    "print(f'MAPE: {mape}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "Lets now add in some independent variables and see how our results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the head of the training independent variables again\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add in BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list called \"inputs\" with \"S5\" and \"BMI\" as elements. \n",
    "# Note notation for lists is []\n",
    "\n",
    "inputs = ['S5','BMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with both inputs, and calculte the new RMSE and MAPE Scores\n",
    "\n",
    "X = sm.add_constant(X_train[inputs])  # adds intercept term\n",
    "y = y_train\n",
    "\n",
    "# Fit model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# make predictions\n",
    "#pred = model.predict(sm.add_constant(X_test[inputs]))\n",
    "pred = model.predict(sm.add_constant(X_train[inputs]))\n",
    "\n",
    "#rmse_2 = root_mean_squared_error(y_test, pred).round(2)\n",
    "rmse_2 = root_mean_squared_error(y_train, pred).round(2)\n",
    "print(f'RMSE_2: {rmse_2}')\n",
    "\n",
    "#mape_2 = mean_absolute_percentage_error(y_test, pred).round(2)*100\n",
    "mape_2 = mean_absolute_percentage_error(y_train, pred).round(2)*100\n",
    "print(f'MAPE_2: {mape_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare these new scores to the previous\n",
    "#rmse_2 = root_mean_squared_error(y_test, pred).round(2)\n",
    "rmse_2 = root_mean_squared_error(y_train, pred).round(2)\n",
    "print(f'RMSE_2: {rmse_2}, Previous RMSE: {rmse}, Improvement = {(rmse - rmse_2).round(2)}' )\n",
    "\n",
    "#mape_2 = mean_absolute_percentage_error(y_test, pred).round(2)*100\n",
    "mape_2 = mean_absolute_percentage_error(y_train, pred).round(2)*100\n",
    "print(f'MAPE_2: {mape_2}%  Previous MAPE: {mape}%, Improvement = {(mape - mape_2).round(2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Observations\n",
    "    We can see here that we have made a marginal improvement by adding BMI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we have built all the models we want to (all 2 of them!) and are ready to test our best model (i.e. the second one) with unknown data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "inputs = ['S5','BMI']\n",
    "pred = model.predict(sm.add_constant(X_test[inputs]))\n",
    "\n",
    "rmse_2 = root_mean_squared_error(y_test, pred).round(2)\n",
    "print(f'RMSE_2: {rmse_2}')\n",
    "\n",
    "mape_2 = mean_absolute_percentage_error(y_test, pred).round(2)*100\n",
    "print(f'MAPE_2: {mape_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of our model-building and evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menti for Quiz on Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix the SEX column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode using one-hot encoding\n",
    "df_dia = pd.get_dummies(df_dia, columns=['SEX'], drop_first=True, dtype=int)\n",
    "\n",
    "df_dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore adding more independent variables\n",
    "\n",
    "Use the code below as a template to add more features and evaluate any changes in output.\n",
    "\n",
    "A good idea would be to save the metrics as element in a dictionary to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dict to hold results\n",
    "# You can add the results for each model to it\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at features\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Run the two cells below repeatedly with different combinations of independent variables then examine the dictionary of stored results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "\n",
    "inputs = [.......]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with both inputs, and calculte the new RMSE and MAPE Scores\n",
    "\n",
    "X = sm.add_constant(X_train[inputs])  # adds intercept term\n",
    "y = y_train\n",
    "\n",
    "# Fit model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# make predictions\n",
    "pred = model.predict(sm.add_constant(X_test[inputs]))\n",
    "\n",
    "\n",
    "# be aware of overwriting previous results, by calling this variable \"rmse\" we overwrite what was previously stored \n",
    "rmse = root_mean_squared_error(y_test, pred).round(2)\n",
    "# printing results\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# be aware of overwriting previous results, by calling this variable \"mape\" we overwrite what was previously stored \n",
    "mape = mean_absolute_percentage_error(y_test, pred).round(2)*100\n",
    "# printing results\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "# adding result to dict\n",
    "results[str(inputs)] = {'RMSE':rmse, \"MAPE\": mape}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out dict of results\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Linear Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
